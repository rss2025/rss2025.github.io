---
layout: page
title: Keynote Talks
description: Keynote talks, with title, abstract and speaker bios.
priority: 8
invisible: false
published: true
---


<div id="k1" class="talk">
  <div class="talk-profile">
    <img src="{{site.baseurl}}/images/Barbara_Webb_2025.jpg"/>
  </div>
  <div class="talk-speaker">
    <h3>Barbara Webb</h3>
    <h4>Professor of Biorobotics, School of Informatics</h4>
    <!-- <h4>School of Informatics</h4> -->
    <h4>University of Edinburgh, Scotland</h4>
  </div>
</div>

<!-- ## Where is RobotGPT? -->
<!-- {: class="talk-title"} -->

<!-- **Abstract:** The last years have seen astonishing progress in the capabilities of generative AI techniques, particularly in the areas of language and visual understanding and generation. Key to the success of these models are the use of image and text data sets of unprecedented scale along with models that are able to digest such large datasets.  We are now seeing the first examples of leveraging such models to equip robots with open-world visual understanding and reasoning capabilities.  Unfortunately, however, we have not achieved the RobotGPT moment; these models still struggle with reasoning about geometry and physical interactions in the real world, resulting in brittle performance on seemingly simple tasks such as manipulating objects in the open world.  A crucial reason for this problem is the lack of data suitable to train powerful, general models for robot decision making and control.
In this talk, I will discuss approaches to generating large datasets for training robot manipulation capabilities, with a focus on the role simulation can play in this context.  I will show some of our prior work, where we demonstrated robust sim-to-real transfer of manipulation skills trained in simulation, and then present a path toward generating large scale demonstration sets that could help train robust, open-world robot manipulation models. -->


<!-- **Bio:** Dieter Fox is Senior Director of Robotics Research at NVIDIA and Professor in the Allen School of Computer Science & Engineering at the University of Washington, where he heads the UW Robotics and State Estimation Lab. Dieter's research is in robotics and artificial intelligence, with a focus on learning and perception applied to problems such as robot manipulation, mapping, and object detection and tracking. He has published more than 200 technical papers and is the co-author of the textbook “Probabilistic Robotics”. He is a Fellow of the IEEE, AAAI, and ACM, and recipient of the 2020 IEEE Pioneer in Robotics and Automation Award and the 2023 IJCAI John McCarthy Award.  He was an editor of the IEEE Transactions on Robotics, program co-chair of the 2008 AAAI Conference on Artificial Intelligence, and program chair of the 2013 Robotics: Science and Systems conference. -->
**Bio:** Barbara Webb obtained a BSc in Psychology at the University of Sydney followed by a PhD in Artificial Intelligence at the University of Edinburgh, where she began her exploration of insect-inspired robots by building a robot cricket (featured in Scientific American). She held faculty positions at the University of Nottingham and University of Stirling before returning to the University of Edinburgh where she is now Professor of Biorobotics in the School of Informatics. She leads the Insect Robotics group, investigating navigation, learning and sensorimotor control, and holds an EPSRC Advanced Career Fellowship to study how insect grasp objects. She has been invited to write reviews describing her pioneering approach to using robots to understand animal behavior for Nature and Science. She was elected a Fellow of the Royal Society of Edinburgh in 2022.

<br/>
<hr>
<br/>



<div id="k2" class="talk">
  <div class="talk-profile">
    <img src="{{site.baseurl}}/images/Trevor_Darrell_2025_cropped.jpg"/>
  </div>
  <div class="talk-speaker">
    <h3>Trevor Darrell</h3>
    <h4>Professor, CS Division</h4>
    <!-- <h4>CS Division</h4> -->
    <!-- <h4>Founding Co-Director, Berkeley Artificial Intelligence Research (BAIR), Berkeley Deep Drive (BDD), and BAIR Commons.</h4> -->
    <h4>University of California, Berkeley, USA</h4>
  </div>
</div>

<!-- ## Making Sense of the Senses in a complex dynamic and uncertain world
{: class="talk-title"} -->

<!-- **Abstract:** Our senses, and those of any organism or agent operating in the same environment as us, are inundated with myriads of diverse signals. How does the brain transform this sensory cacophony into a coherent percept of the world? Why does perception sometimes falter, resulting in illusions? This talk will explore how sensory integration can trick the human brain into believing that a puppet is speaking, a rubber hand belongs to our own body or that ‘da’ is heard instead of ‘ba’. I will demonstrate that both accurate and illusionary perceptions result from the brain’s strategy to integrate sensory information based on Bayesian principles. 

Specifically, I will show that the brain near-optimally integrates sensory signals arising from common causes into more precise percepts by weighting them in relation to their momentary uncertainties. Moving to more complex scenarios, I will discuss situations where signals may originate from common or independent sources. In these cases, the brain needs to solve the binding problem—determining whether signals come from common causes and should hence be integrated or else be processed independently. I will show that the brain arbitrates between sensory integration and segregation consistent with principles of hierarchical Bayesian causal inference. Finally, I will explore how the brain may employ attentional mechanisms to compute approximate solutions to the binding problem in realistic environments where numerous signals and sources make optimal Bayesian inference infeasible for the brain’s limited computational capacities. 

Overall, our research highlights the critical role of sensory integration based on Bayesian principles in enabling the brain to resolve perceptual ambiguities and reduce its uncertainties about the world. Since robots need to operate in similar sensory environments and thus face comparable challenges, these insights may have important implications for robotic perception and decision making.


**Bio:** Uta Noppeney is Professor of Systems Neuroscience at the Neurophysics department and a Principal Investigator at the Donders Centres for Cognitive Neuroimaging and Neuroscience within the Donders Institute for Brain, Cognition and Behaviour. Previously, she was a Professor of Computational Neuroscience and director of the Computational Neuroscience and Cognitive Robotics Centre at the University of Birmingham (UK) and independent research group leader at the Max Planck Institute for Biological Cybernetics, Tuebingen (Germany). Her research investigates the computational and neural mechanisms of perceptual inference, learning and attention in dynamic multisensory environments. She uses a multidisciplinary approach integrating psychophysics, computational modelling (Bayesian, neural network) and advanced neuroimaging techniques (fMRI, MEG, EEG, TMS). She is the recipient of a Young Investigator Award of the Cognitive Neuroscience Society in 2013, a Turing Fellowship in 2018, an ERC starting grant in 2013 and an ERC advanced grant in 2023. She is also a member of the Academia Europaea and an academic editor of PLOS Biology and Multisensory Research. -->

**Bio:** Prof. Darrell is on the faculty of the CS and EE Divisions of the EECS Department at UC Berkeley. He founded and co-leads Berkeley’s Berkeley Artificial Intelligence Research (BAIR) lab, the Berkeley DeepDrive (BDD) Industrial Consortia, and the BAIR Commons program.   He also was Faculty Director of the PATH research center at UC Berkeley from 2015-2021, and led the Vision group at the UC-affiliated International Computer Science Institute in Berkeley from 2008-2014. Prior to that, Prof. Darrell was on the faculty of the MIT EECS department from 1999-2008, where he directed the Vision Interface Group. He was a member of the research staff at Interval Research Corporation from 1996-1999, and received the S.M., and PhD. degrees from MIT in 1991 and 1996, respectively. He obtained the B.S.E. degree from the University of Pennsylvania in 1988. 
Darrell’s group develops algorithms for large-scale perceptual learning, including object and activity recognition and detection, for a variety of applications including autonomous vehicles, media search, and multimodal interaction with robots and mobile devices. His areas of interest include computer vision, machine learning, natural language processing, and perception-based human computer interfaces.

Prof. Darrell also co-founded and serves as President of Prompt AI. Darrell is an advisor to several other ventures, including SafelyYou, Nexar, and SuperAnnotate. Previously, Darrell advised Pinterest, Tyzx (acquired by Intel), IQ Engines (acquired by Yahoo), Koozoo, BotSquare/Flutter (acquired by Google), MetaMind (acquired by Salesforce), Trendage, Center Stage, KiwiBot, WaveOne, DeepScale, and Grabango. Darrell has also served as an expert witness for patent litigation relating to computer vision.
