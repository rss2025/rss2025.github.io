---
layout: paper
title: "Gripper Pose and Object Pointflow as Interfaces for Robotic Bimanual Manipulation"
invisible: true
prev_id: "159"
next_id: "161"
---
<div class="paper-authors">
  <div class="paper-author-box">
    <div class="paper-author-name">Yuyin Yang, Zetao Cai, Yang Tian, Jia Zeng, Jiangmiao Pang</div>
    <div class="paper-author-uni"></div>
  </div>
</div>

<div class="paper-pdf">
  <div>
    <a href="https://www.roboticsproceedings.org/rss21/p160.pdf" title="Download PDF" target="_blank">
      <img src="{{ site.baseurl }}/images/paper_link_cardinal_red.png" alt="Paper PDF" width="33" height="40" />
    </a>
  </div>
</div>

### Paper ID 160
{: style="margin-top: 10px; text-align: center;" }

### [Session 17. Imitation Learning II]({{ site.baseurl }}/program/papersession?session=17.%20Imitation%20Learning%20II)
{: style="text-align: center;" }

#### Poster Session (Day 4): Tuesday, June 24, 4:00-5:30 PM
{: style="margin-top: 10px; color: #555555; text-align: center;" }

<b style="color: black;">Abstract: </b>Bimanual manipulation is a complex yet essential capability in robotics, requiring exceptional precision in spatial localization and temporal coordination, challenging current methodologies. Existing approaches fall into two categories: keyframe-based strategies, which predict gripper poses in keyframes and execute them via motion planners, and continuous control methods, which estimate actions sequentially at each timestep. The keyframe-based method lacks inter-frame supervision, struggling to perform consistently or execute curved motions, while the continuous method suffers from weaker spatial perception. To address these issues, this paper introduces an end-to-end framework PPI (keyPose and Pointflow Interface), that integrates the prediction of target gripper poses and object point flow with continuous actions estimation. These interfaces enable the model to effectively attend to the target manipulation area, while the overall framework guides coordinated and collision-free dense actions. By combining interface predictions with continuous actions estimation, PPI demonstrates superior performance in diverse bimanual manipulation tasks, providing enhanced spatial localization and temporal coordination. In extensive evaluations, PPI significantly outperforms prior methods in both simulated and real-world experiments, achieving the state-of-the-art performance on the RLBench2 simulation benchmark and across four challenging real-world tasks. Notably, PPI exhibits strong stability, high precision, and remarkable generalization capabilities in real-world scenarios. Code and models will be released.
{: style="color:gray; font-size: 120%; text-align: justified;" }

<div class="paper-menu">
  <div class="paper-menu-inner">
    <a href="{{ site.baseurl }}/program/papers/159/" title="Previous Paper">
            <div class="paper-menu-icon">
                <i class="fa fa-chevron-left"></i><br>
                <span class="paper-menu-label">Back</span>
            </div>
        </a>
    <a href="{{ site.baseurl }}/program/papers" title="All Papers">
      <div class="paper-menu-icon">
        <i class="fa fa-list"></i><br>
        <span class="paper-menu-label">Papers</span>
      </div>
    </a>
    <a href="{{ site.baseurl }}/program/papers/161/" title="Next Paper">
            <div class="paper-menu-icon">
                <i class="fa fa-chevron-right"></i><br>
                <span class="paper-menu-label">Next</span>
            </div>
        </a>
  </div>
</div>
