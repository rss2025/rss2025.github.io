---
layout: paper
title: "Learning Getting-Up Policies for Real-World Humanoid Robots"
invisible: true
prev_id: "S7.2"
next_id: "S7.4"
---
<div class="paper-authors">
  <div class="paper-author-box">
    <div class="paper-author-name">Xialin He, Runpei Dong, Zixuan Chen, Saurabh Gupta</div>
    <div class="paper-author-uni"></div>
  </div>
</div>

<div class="paper-pdf-modern">
  <div class="paper-menu-icon">
    <a href="https://www.roboticsproceedings.org/rss25/p106.pdf" title="Download PDF" target="_blank">
      <i class="fa fa-file-pdf-o"></i><br>
      <span class="paper-menu-label">PDF</span>
    </a>
  </div>
</div>

### Paper ID S7.3
{: style="margin-top: 10px; text-align: center;" }

### [Session 7. Humanoids]({{ site.baseurl }}/program/papersession?session=7.%20Humanoids)
{: style="text-align: center;" }

<b style="color: black;">Abstract: </b>Automatic recovery from falls is a crucial prerequisite before humanoid robots can be reliably deployed. Hand-designing controllers for getting up is difficult because of the varied configurations a humanoid can end up in after a fall and the challenging terrains humanoid robots are expected to operate on. This paper develops a learning framework to produce controllers that enable humanoid robots to get up from varying configurations on varying terrains. Different from previous successful applications of humanoid locomotion learning, the getting-up task involves complex contact patterns, the necessity to accurately model collision geometry, and sparser rewards. We circumvent these challenges through a two-phase approach that follows a curriculum. The first stage focuses on discovering a good get up trajectory under minimal constraints on smoothness or speed / torque limits. The second stage then refines the discovered motions into deployable (<em>i.e.</em> smooth and slow) motions that are robust to variations in initial configuration and terrains.  We find these innovations enable a real-world G1 humanoid robot to get up from two main situations that we considered:  a) lying face up and b) lying face down, both tested on flat, deformable, slippery surfaces and slopes (e.g., sloppy grass and snowfield). To the best of our knowledge, this is the first successful demonstration of learned getting-up policies for humanoid robots in the real world.
{: style="color:gray; font-size: 120%; text-align: justified;" }

<div class="paper-menu">
  <div class="paper-menu-inner">
    <a href="{{ site.baseurl }}/program/papers/S7.2/" title="Previous Paper">
            <div class="paper-menu-icon">
                <i class="fa fa-chevron-left"></i><br>
                <span class="paper-menu-label">Back</span>
            </div>
        </a>
    <a href="{{ site.baseurl }}/program/papers" title="All Papers">
      <div class="paper-menu-icon">
        <i class="fa fa-list"></i><br>
        <span class="paper-menu-label">All Papers</span>
      </div>
    </a>
    <a href="{{ site.baseurl }}/program/papers/S7.4/" title="Next Paper">
            <div class="paper-menu-icon">
                <i class="fa fa-chevron-right"></i><br>
                <span class="paper-menu-label">Next</span>
            </div>
        </a>
  </div>
</div>
