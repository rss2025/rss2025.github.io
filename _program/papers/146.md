---
layout: paper
title: "Novel Demonstration Generation with Gaussian Splatting Enables Robust One-Shot Manipulation"
invisible: true
prev_id: "145"
next_id: "147"
---
<div class="paper-authors">
  <div class="paper-author-box">
    <div class="paper-author-name">Sizhe Yang, Wenye Yu, Jia Zeng, Jun Lv, Kerui Ren, Cewu Lu, Dahua Lin, Jiangmiao Pang</div>
    <div class="paper-author-uni"></div>
  </div>
</div>

<div class="paper-pdf">
  <div>
    <a href="https://www.roboticsproceedings.org/rss21/p146.pdf" title="Download PDF" target="_blank">
      <img src="{{ site.baseurl }}/images/paper_link_cardinal_red.png" alt="Paper PDF" width="33" height="40" />
    </a>
  </div>
</div>

### Paper ID 146
{: style="margin-top: 10px; text-align: center;" }

### [Session 16. Manipulation III]({{ site.baseurl }}/program/papersession?session=16.%20Manipulation%20III)
{: style="text-align: center;" }

#### Poster Session (Day 4): Tuesday, June 24, 12:30-2:00 PM
{: style="margin-top: 10px; color: #555555; text-align: center;" }

<b style="color: black;">Abstract: </b>Visuomotor policies learned through imitation learning methods often struggle to generalize to new visual domains due to the limited diversity of expert demonstrations, and collecting extensive real-world data is exhaustive.  To address this challenge, we propose a novel demonstration generation approach leveraging 3D Gaussian Splatting (3DGS), an explicit and interpretable means of 3D scene representation.  Our method reconstructs manipulation scenes with high fidelity and enables autonomous scene editing, giving rise to novel scene configurations. Stemming from a single expert demonstration, diversified data are generated across various visual domains, including different object poses, object types, camera views, scene appearance, lighting conditions, and robot embodiments.  Comprehensive real-world experiments suggest that our demonstration generation pipeline significantly enhances the generalization of visuomotor policies when confronting multiple disturbances. Specifically, while policies trained on real-world demonstrations achieve an average success rate of less than 10%, our method lifts this number to 85.9% across various task settings and scenarios.
{: style="color:gray; font-size: 120%; text-align: justified;" }

<div class="paper-menu">
  <div class="paper-menu-inner">
    <a href="{{ site.baseurl }}/program/papers/145/" title="Previous Paper">
            <div class="paper-menu-icon">
                <i class="fa fa-chevron-left"></i><br>
                <span class="paper-menu-label">Back</span>
            </div>
        </a>
    <a href="{{ site.baseurl }}/program/papers" title="All Papers">
      <div class="paper-menu-icon">
        <i class="fa fa-list"></i><br>
        <span class="paper-menu-label">Papers</span>
      </div>
    </a>
    <a href="{{ site.baseurl }}/program/papers/147/" title="Next Paper">
            <div class="paper-menu-icon">
                <i class="fa fa-chevron-right"></i><br>
                <span class="paper-menu-label">Next</span>
            </div>
        </a>
  </div>
</div>
