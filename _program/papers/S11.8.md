---
layout: paper
title: "CordViP: Correspondence-based Visuomotor Policy for Dexterous Manipulation in Real-World"
invisible: true
prev_id: "S11.7"
next_id: "S11.9"
---
<div class="paper-authors">
  <div class="paper-author-box">
    <div class="paper-author-name">Yankai Fu, Ning Chen, Qiuxuan Feng, Zichen Zhou, Mengzhen Liu, Mingdong Wu, Tianxing Chen, Shanyu Rong, Jiaming Liu, Hao Dong, Shanghang Zhang</div>
    <div class="paper-author-uni"></div>
  </div>
</div>

<div class="paper-pdf-modern">
  <div class="paper-menu-icon">
    <a href="https://www.roboticsproceedings.org/rss25/p257.pdf" title="Download PDF" target="_blank">
      <i class="fa fa-file-pdf-o"></i><br>
      <span class="paper-menu-label">PDF</span>
    </a>
  </div>
</div>

### Paper ID S11.8
{: style="margin-top: 10px; text-align: center;" }

### [Session 11. Manipulation II]({{ site.baseurl }}/program/papersession?session=11.%20Manipulation%20II)
{: style="text-align: center;" }

<b style="color: black;">Abstract: </b>Achieving human-level dexterity in robots is a key objective in the field of robotic manipulation. Recent advancements in 3D-based imitation learning have shown promising results, providing an effective pathway to achieve this goal. However, obtaining high-quality 3D representations presents two key problems:  (1) the quality of point clouds captured by a single-view camera is significantly affected by factors such as camera resolution, positioning, and occlusions caused by the dexterous hand; (2) the global point clouds lack crucial contact information and spatial correspondences, which are necessary for fine-grained dexterous manipulation tasks. To eliminate these limitations, we propose  CordViP, a novel framework that constructs and learns correspondences by leveraging the robust 6D pose estimation of objects and robot proprioception. Specifically, we first introduce the interaction-aware point clouds, which establish correspondences between the object and the hand. These point clouds are then used for our pretraining strategy, where we also incorporate object-centric contact maps and hand-arm coordination information, effectively capturing both spatial and temporal dynamics.  Our method demonstrates exceptional dexterous manipulation capabilities with an average success rate of 90% in four real-world tasks, surpassing other baselines by a large margin. Experimental results also highlight the superior generalization and robustness of CordViP to different objects, viewpoints, and scenarios.
{: style="color:gray; font-size: 120%; text-align: justified;" }

<div class="paper-menu">
  <div class="paper-menu-inner">
    <a href="{{ site.baseurl }}/program/papers/S11.7/" title="Previous Paper">
            <div class="paper-menu-icon">
                <i class="fa fa-chevron-left"></i><br>
                <span class="paper-menu-label">Back</span>
            </div>
        </a>
    <a href="{{ site.baseurl }}/program/papers" title="All Papers">
      <div class="paper-menu-icon">
        <i class="fa fa-list"></i><br>
        <span class="paper-menu-label">All Papers</span>
      </div>
    </a>
    <a href="{{ site.baseurl }}/program/papers/S11.9/" title="Next Paper">
            <div class="paper-menu-icon">
                <i class="fa fa-chevron-right"></i><br>
                <span class="paper-menu-label">Next</span>
            </div>
        </a>
  </div>
</div>
