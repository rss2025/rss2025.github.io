---
layout: page
title: Early Career Spotlight
description: Early Career Talks, with title, abstract and speaker bios.
priority: 7
invisible: false
published: true
---


<div id="ec1" class="talk">
  <div class="talk-profile">
    <img src="{{site.baseurl}}/images/ec_spotlight_2.jpg"/>
  </div>
  <div class="talk-speaker">
    <h3>Stefan Leutenegger</h3>
    <h4>Assistant Professor</h4>
    <h4>School of Computation, Information and Technology </h4>
    <h4>Technical University of Munich (TUM) </h4>
  </div>
</div>

## Spatial Perception for Real-World Mobile Robots including Drones
{: class="talk-title"}

**Abstract:** To power the next generation mobile robots and drones, the field of spatial perception has made much progress from robust multi-sensor SLAM to dense, semantic, and object-level maps, with the aim of understanding open-ended environments as a basis for mobile robot navigation and environment interaction. I will show recent progress in reliable and real-time state estimation and 3D scene understanding using vision, LiDAR, IMUs, and more. Scenes to be reconstructed may contain dynamic objects and even people, whose poses, postures, and motions we can estimate in a tightly-coupled manner. In our works, we fully embrace the power of machine learning-based approaches, but typically integrated in modular, complex robotic systems that may include model-based methods as well. Our approaches are demonstrated as crucial enablers of a range of robot applications, from mobile manipulation on construction sites to drones exploring obstructed indoor spaces or flying through the forest.

**Bio:** Stefan is an Assistant Professor (Tenure Track) at the Technical University of Munich (TUM) in the School of Computation, Information and Technology (CIT) and has further affiliations with the Munich Institute of Robotics and Machine Intelligence (MIRMI) as well as the Munich Data Science Institute (MDSI) and the Munich Center for Machine Learning (MCML). He leads the Smart Robotics Lab (SRL) working at the intersection of perception, mobile robotics, drones, and machine learning. Stefan also still holds the position of a visiting Reader at the Department of Computing of Imperial College London, his previous post. He has also co-founded SLAMcore, a spin-out company aiming at commercialisation of localisation and mapping solutions for robots and drones. Stefan has received a BSc and from ETH Zurich, as well as a PhD on “Unmanned solar airplanes: design and algorithms for efficient and robust autonomous operation” in 2014.

<br/>
<hr>
<br/>

<!-- 
<div id="ec2" class="talk">
  <div class="talk-profile">
    <img src="{{site.baseurl}}/images/ec_spotlight_1.jpg"/>
  </div>
  <div class="talk-speaker">
    <h3>Michael Posa</h3>
    <h4>Assistant Professor</h4>
    <h4>Mechanical Engineering and Applied Mechanics</h4>
    <h4>University of Pennsylvania</h4>
  </div>
</div>

## The Structure of Touch: Low-Data Learning and Control
{: class="talk-title"}

**Abstract:** Machine learning has shown incredible promise in robotics, with some notable recent demonstrations in manipulation and sim-to-real transfer. These results, however, require either simulating an accurate model or a large amount of data. For robots to deploy to our homes and workplaces, they will inevitably encounter new objects, tasks, and environments. How will they adapt to this novelty, given only few minutes to gather information and accomplish some complex task? I will first argue that the hybrid or contact-driven aspects of manipulation clashes with the inductive biases inherent in standard learning methods, driving the current need for large data. I will then show how contact-inspired implicit learning, embedding convex optimization, can reshape the loss landscape and enable more accurate training, better generalization, and ultimately data efficiency. Finally, I will present our latest results on how these learned models can be deployed via real-time multi-contact MPC for robotic manipulation.

**Bio:** Michael Posa is an Assistant Professor in Mechanical Engineering and Applied Mechanics at the University of Pennsylvania. He leads the Dynamic Autonomy and Intelligent Robotics (DAIR) lab, a group within the Penn GRASP laboratory.  His group focuses on developing computationally tractable algorithms to enable robots to operate both dynamically and safely as they interact with their environments. Michael received his Ph.D. in Electrical Engineering and Computer Science from MIT in 2017, where, among his other research, he spent time on the MIT DARPA Robotics Challenge team. He received his B.S. in Mechanical Engineering from Stanford University in 2007. Before his doctoral studies, he worked as an engineer at Vecna Robotics. He has received the Best Paper award at HSCC and been finalist awards at TRO, ICRA, and IEEE Humanoids. He received the NSF CAREER Award in 2023, a Google Faculty Research Award in 2019, and the Young Faculty Researcher Award from the Toyota Research Institute in 2021.
-->