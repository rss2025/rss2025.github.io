---
layout: page
title: Early Career Spotlight
description: Early Career Talks, with title, abstract and speaker bios.
priority: 7
invisible: false
published: true
---


<div id="ec1" class="talk">
  <div class="talk-profile">
    <img src="{{site.baseurl}}/images/Dorsa_Sadigh_2025.jpg"/>
  </div>
  <div class="talk-speaker">
    <h3>Dorsa Sadigh</h3>
    <h4>Associate Professor of Computer Science</h4>
    <h4>Stanford University</h4>
    <h4>Senior Fellow, Stanford HAI</h4>
    <h4>Research Scientist, Google DeepMind</h4>
  </div>
</div>

## From Dirt to Data: How Gardening Taught me about Generalist Robot Policies
{: class="talk-title"}

**Abstract:** In this talk, I will share my journey toward building generalist robot policies—and how it surprisingly mirrors the process of cultivating my backyard garden. I’ll begin by unpacking the key components of robotics foundation models and their promise for generalization across diverse tasks and environments. To ground this discussion, I will introduce StarGen, a taxonomy for evaluating generalization in robot policies, spanning semantic, visual, and behavioral dimensions. Next, I’ll explore what truly enables generalization both algorithmically and in terms of data—drawing an analogy to the delicate process of paintbrush pollination in gardening. I’ll present RT-H: Action Hierarchies using Language Motion, a framework that leverages low-level language abstractions—language motions—to stitch together diverse sources of data. Building on this, I’ll discuss the broader concept of intermediate representations—such as bounding boxes, language-conditioned motions, and trajectory traces—that help bridge the gap between the perceptual strengths of vision-language models and the physical execution required by robots. On the data side, I’ll introduce RoboCrowd, a scalable approach to collecting robotic demonstrations through crowdsourcing and incentive design. I’ll conclude with a look at GeminiRobotics, a system showcasing steerable and interactive capabilities, and discuss its potential to shape the future of human-robot interaction.

**Bio:** Dorsa Sadigh is an associate professor in Computer Science and an HAI senior fellow at Stanford University. She is also a research scientist at Google DeepMind.  Her research interests lie in the intersection of robot learning and human-robot interaction. Specifically, she is interested in developing algorithms for adaptive learning agents that can learn from humans and interact with them. Dorsa received her doctoral degree in Electrical Engineering and Computer Sciences (EECS) from UC Berkeley in 2017, and received her bachelor’s degree in EECS from UC Berkeley in 2012.  She is awarded the Sloan Fellowship, PECASE award, NSF CAREER award, ONR Young Investigator award, and MIT TR35.


<br/>
<hr>
<br/>

<!-- 
<div id="ec2" class="talk">
  <div class="talk-profile">
    <img src="{{site.baseurl}}/images/ec_spotlight_1.jpg"/>
  </div>
  <div class="talk-speaker">
    <h3>Michael Posa</h3>
    <h4>Assistant Professor</h4>
    <h4>Mechanical Engineering and Applied Mechanics</h4>
    <h4>University of Pennsylvania</h4>
  </div>
</div>

## The Structure of Touch: Low-Data Learning and Control
{: class="talk-title"}

**Abstract:** Machine learning has shown incredible promise in robotics, with some notable recent demonstrations in manipulation and sim-to-real transfer. These results, however, require either simulating an accurate model or a large amount of data. For robots to deploy to our homes and workplaces, they will inevitably encounter new objects, tasks, and environments. How will they adapt to this novelty, given only few minutes to gather information and accomplish some complex task? I will first argue that the hybrid or contact-driven aspects of manipulation clashes with the inductive biases inherent in standard learning methods, driving the current need for large data. I will then show how contact-inspired implicit learning, embedding convex optimization, can reshape the loss landscape and enable more accurate training, better generalization, and ultimately data efficiency. Finally, I will present our latest results on how these learned models can be deployed via real-time multi-contact MPC for robotic manipulation.

**Bio:** Michael Posa is an Assistant Professor in Mechanical Engineering and Applied Mechanics at the University of Pennsylvania. He leads the Dynamic Autonomy and Intelligent Robotics (DAIR) lab, a group within the Penn GRASP laboratory.  His group focuses on developing computationally tractable algorithms to enable robots to operate both dynamically and safely as they interact with their environments. Michael received his Ph.D. in Electrical Engineering and Computer Science from MIT in 2017, where, among his other research, he spent time on the MIT DARPA Robotics Challenge team. He received his B.S. in Mechanical Engineering from Stanford University in 2007. Before his doctoral studies, he worked as an engineer at Vecna Robotics. He has received the Best Paper award at HSCC and been finalist awards at TRO, ICRA, and IEEE Humanoids. He received the NSF CAREER Award in 2023, a Google Faculty Research Award in 2019, and the Young Faculty Researcher Award from the Toyota Research Institute in 2021.
-->